## üìå C++ Thread Synchronization Mechanisms

### **1Ô∏è‚É£ Mutual Exclusion (Protects Shared Resources)**
| Mechanism       | Description |
|----------------|------------|
| **`std::mutex`** | Ensures **only one thread** accesses a shared resource at a time. |
| **`std::recursive_mutex`** | Allows **the same thread** to lock multiple times (useful for recursive functions). |
| **`std::timed_mutex`** | Like `std::mutex`, but allows a **timeout** when trying to lock. |
| **`std::shared_mutex`** | Allows **multiple readers but only one writer** (reader-writer lock). |

üìå **Use Case**: Protecting **shared data structures** from concurrent modifications.

---

### **2Ô∏è‚É£ Thread Coordination (Synchronization Between Threads)**
| Mechanism       | Description |
|----------------|------------|
| **`std::condition_variable`** | Lets threads **wait** for an event and be **notified** when ready. |
| **`std::condition_variable_any`** | Like `condition_variable`, but works with **any lock type**. |
| **`std::barrier`** (C++20) | Synchronizes **multiple threads at specific points** (multi-stage processing). |
| **`std::latch`** (C++20) | Allows threads to **wait until a counter reaches zero** (one-time use). |
| **`std::semaphore`** (C++20) | Limits **how many threads** can access a resource concurrently. |

üìå **Use Case**: **Waiting for data availability**, **multi-stage processing**, **rate-limiting access**.

---

### **3Ô∏è‚É£ Atomic Operations**
| Mechanism       | Description |
|----------------|------------|
| **`std::atomic<T>`** | Provides **thread-safe** operations on variables **without locks**. |
| **`std::atomic_flag`** | A simple atomic boolean flag (set/reset). |

üìå **Use Case**: **Incrementing counters, lock-free data structures, low-latency operations**.

---

### **4Ô∏è‚É£ Smart Locking (Automatic Lock Management)**
| Mechanism       | Description |
|----------------|------------|
| **`std::lock_guard<std::mutex>`** | Auto-locks a mutex for a **single critical section** (RAII style). |
| **`std::unique_lock<std::mutex>`** | More flexible than `lock_guard` (supports deferred locking, unlocking, and moving). |
| **`std::scoped_lock`** (C++17) | Locks **multiple mutexes at once** (prevents deadlocks). |

üìå **Use Case**: **Automatic locking & unlocking** to prevent forgetting to unlock a `mutex`.

---

## **üöÄ Which One to Use?**
| Scenario | Best Mechanism |
|----------|---------------|
| **Protect shared data** (only one thread at a time) | `std::mutex` ‚úÖ |
| **Multiple readers, one writer** | `std::shared_mutex` ‚úÖ |
| **Limit access to N threads** (e.g., thread pool, database connections) | `std::semaphore` ‚úÖ |
| **Wait for an event before proceeding** | `std::condition_variable` ‚úÖ |
| **Thread-safe counter** | `std::atomic<int>` ‚úÖ |
| **Synchronize multiple threads at stages** | `std::barrier` ‚úÖ |
| **Wait for N tasks to finish before proceeding** | `std::latch` ‚úÖ |


## `std::atomic` vs `std::mutex` in C++

Both `std::atomic` and `std::mutex` are used for thread synchronization in C++, but they serve different purposes and have different performance characteristics.

## **Comparison Table**

| Feature            | `std::atomic` | `std::mutex` |
|-------------------|--------------|-------------|
| **Purpose** | Provides atomic operations on a single variable | Provides mutual exclusion for protecting critical sections |
| **Granularity** | Works at the level of individual variables | Protects multiple variables or entire code blocks |
| **Locking Mechanism** | Lock-free (where supported), non-blocking | Requires explicit locking (`lock()`, `unlock()`) |
| **Performance** | Faster (avoids kernel overhead) | Slower (involves OS-level locks) |
| **Use Case** | Simple atomic operations (counters, flags, pointers) | Complex operations involving multiple shared resources |
| **Thread Blocking** | Never blocks; always non-blocking | Can block waiting threads |
| **Memory Overhead** | Low overhead | Higher overhead due to system calls |

---


## **When to Use `std::atomic`**
Use `std::atomic` when:
- You need to protect **a single variable** (like a counter or a flag).
- Lock-free operations improve performance.
- You are working with **simple operations** like incrementing, decrementing, or exchanging values.

## **When to Use `std::mutex`**
Use `std::mutex` when:
- You need to protect **multiple variables** or **complex data structures** (e.g., modifying multiple members of a class).
- You require **atomicity across multiple operations**.
- The performance overhead of a mutex is acceptable.

## Deadlock avoidance
1. Avoid nested locks.
2. Establish a uniform order for blocking mutexes - Always block mutexes in the same order across all threads.
3. Use std::lock() to avoid deadlocks - std::lock() locks multiple mutexes at once, preventing deadlocks
4. Use std::lock_guard/std::scoped_lock to guarantee mutex unlock


# Locks comparison


| Feature              | `std::lock_guard` | `std::unique_lock` | `std::scoped_lock` |
|----------------------|------------------|--------------------|--------------------|
| **Introduced In**    | C++11            | C++11             | C++17             |
| **Purpose**         | Simple, automatic mutex locking | More flexible mutex handling | Locks multiple mutexes at once |
| **Locking Mechanism** | Locks immediately on construction | Can defer, move, or manually unlock | Locks immediately on construction |
| **Unlocking Support** | ‚ùå No manual unlock | ‚úÖ Can unlock manually (`unlock()`) | ‚ùå No manual unlock |
| **Multiple Mutexes** | ‚ùå No | ‚ùå No | ‚úÖ Yes (prevents deadlocks) |
| **Performance** | ‚ö° Fast, minimal overhead | üê¢ Slight overhead due to flexibility | ‚ö° Fast, optimized for multiple mutexes |
| **Best Use Case** | Simple, scoped locking | When flexibility is needed (e.g., deferred locking, moving ownership) | When locking multiple mutexes safely |


# Barrier
1. ‚úÖ Parallel Processing Pipelines ‚Äì Synchronize different stages of computation.
2. ‚úÖ Multi-Threaded Algorithms ‚Äì Ensure all threads complete a step before moving forward.
3. ‚úÖ Data Processing in Batches ‚Äì Process chunks of data in parallel and synchronize between batches.


## üìå Comparison: `std::barrier` vs `std::latch`

| Feature            | `std::barrier`                        | `std::latch`                          |
|--------------------|--------------------------------------|--------------------------------------|
| **Type**          | Reusable Synchronization Mechanism   | One-Time Countdown Synchronization |
| **Resets Automatically?** | ‚úÖ Yes (after all threads arrive) | ‚ùå No (one-time use) |
| **Callback Function?** | ‚úÖ Yes (executed after all threads arrive) | ‚ùå No |
| **When to Use?**  | Synchronize threads **at multiple stages** (e.g., iterative parallel algorithms) | Synchronize threads **only once** (e.g., waiting for initialization) |
